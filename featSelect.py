import pandas as pd
import numpy as np
import sklearn.svm as sksvm
import sklearn.model_selection as skm
import sklearn.feature_selection as skf
import matplotlib.pyplot as plt
import sklearn.metrics as skmet
import sklearn.ensemble as ske
import sklearn.linear_model as skl

a1 = a2 = a3 = []
high_score = 0
high_no = 0
df = pd.read_csv('Features.csv')
feat = df.drop(df.columns[[0, -1]], axis = 1, inplace = False)
cols = feat.columns
X = feat.values
Y = df['Class'].values

m1 = sksvm.SVC()
m2 = ske.RandomForestClassifier()
m3 = skl.LogisticRegression()

X_train, X_test, Y_train, Y_test = skm.train_test_split(X, Y, test_size = 0.3)
for i in range(10, 1557, 50):
    fs = skf.SelectKBest(score_func = skf.chi2, k = i)
    fs.fit(X, Y)
    X_fit = fs.transform(X_train)
    X_test_fit = fs.transform(X_test)
    m1.fit(X_fit,Y_train)
    m2.fit(X_fit,Y_train)
    m3.fit(X_fit,Y_train)
    s1 = m1.score(X_test_fit, Y_test)
    s2 = m2.score(X_test_fit, Y_test)
    s3 = m3.score(X_test_fit, Y_test)
    a1.append(s1)
    a2.append(s2)
    a3.append(s3)
    print("SVM with ", i, " features : ", s1)
    print("Log with ", i, " features : ", s2)
    print("RF with ", i, " features : ", s3)
plt.plot(range(10, 1557, 50), a1, label = 'SVM')
plt.plot(range(10, 1557, 50), a2, label = 'Logistic Regression')
plt.plot(range(10, 1557, 50), a3, label = 'Random Forest')
plt.xlabel('Number of Features')
plt.ylabel('Score')
plt.legend()
plt.savefig('FeatureSelect3.png')
